{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adee586-1eb4-4578-b492-f93135f8e7d4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#specifying wich gpu to use because there is no option for that in Trainer \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import default_data_collator\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ebda4-b540-4bac-a5cd-30c584981def",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_train = os.path.join(\"train_short_impossible.csv\")\n",
    "train_df = pd.read_csv(\"train_short_impossible.csv\", sep = \";\", index_col=0, na_filter=False)\n",
    "# \n",
    "\n",
    "path_dev = os.path.join(\"dev_short_impossible.csv\")\n",
    "dev_df = pd.read_csv(\"dev_short_impossible.csv\", sep = \";\", index_col=0, na_filter=False)\n",
    "# \n",
    "train_df['is_impossible'] = train_df['is_impossible'].apply(int)\n",
    "dev_df['is_impossible'] = dev_df['is_impossible'].apply(int)\n",
    "\n",
    "train_df = train_df.drop(['end','start', 'user', 'title', 'section', 'answer', 'type', 'modanswer'], axis=1)\n",
    "dev_df = dev_df.drop(['end','start', 'user', 'title', 'section', 'answer', 'type', 'modanswer'], axis=1)\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace('is_impossible', 'label')\n",
    "dev_df.columns = dev_df.columns.str.replace('is_impossible', 'label')\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637854b5-0c21-4516-a4b6-0bb4348b14ef",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#deepset/xlm-roberta-large-squad2\n",
    "#mcsabai/huBert-fine-tuned-hungarian-squadv2\n",
    "id2label = {0: \"False\", 1: \"True\"}\n",
    "label2id = {\"False\": 0, \"True\": 1}\n",
    "model_checkpoint = \"SZTAKI-HLT/hubert-base-cc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = BertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2375c-328b-40b6-a586-6b2bd6659093",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    \n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    \n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "           \n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d732f-83a7-4f2e-a2db-993ba5aac374",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_tokenized_dataset = train_dataset.map(prepare_train_features, batched=True)\n",
    "train_tokenized_dataset = train_tokenized_dataset.remove_columns(['token_type_ids', 'id', 'question', '__index_level_0__'])\n",
    "dev_tokenized_dataset = dev_dataset.map(prepare_train_features, batched=True)\n",
    "dev_tokenized_dataset=dev_tokenized_dataset.remove_columns(['token_type_ids', 'id', 'question','__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a20d9-7d65-4c88-8ac8-05b288f96f2d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d64f1-c2f7-4388-a4e7-5dcf5c7c29a7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 2e-5\n",
    "epochs = 3\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = 'no',\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53252a-03be-49b5-983e-e0d814eb6902",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cuda:0')\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=dev_tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520ea15-35f1-4dc2-96a4-7656df2cb3bb",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}